{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75c3db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MICROSOFT GEOLIFE GPS TRAJECTORY DATASET LOADER\n",
      "============================================================\n",
      "\n",
      "Data directory: c:\\Users\\subha\\Desktop\\Projects\\dementia_detection\\data\\microsoft_geolife\\Data\n",
      "\n",
      "This will load ALL .plt files from 182 user folders (000-181)\n",
      "Each user has multiple trajectory files in their Trajectory/ subfolder\n",
      "\n",
      "============================================================\n",
      "LOADING GEOLIFE DATASET: Users 000 to 181\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users:  11%|█         | 20/182 [01:31<09:03,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  User 019: 47,824 points | Total so far: 4,997,092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users:  22%|██▏       | 40/182 [02:42<08:01,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  User 039: 267,737 points | Total so far: 9,206,855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users:  33%|███▎      | 60/182 [03:29<02:11,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  User 059: 23,606 points | Total so far: 11,601,490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users:  45%|████▍     | 81/182 [10:51<04:09,  2.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  User 079: 11,243 points | Total so far: 14,348,129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users:  55%|█████▌    | 101/182 [14:46<01:40,  1.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  User 099: 1,267 points | Total so far: 16,021,938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users:  67%|██████▋   | 122/182 [15:26<01:15,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  User 119: 103,734 points | Total so far: 16,533,633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users:  77%|███████▋  | 140/182 [30:34<06:00,  8.59s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  User 139: 1,353 points | Total so far: 18,754,926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users:  88%|████████▊ | 161/182 [47:10<10:01, 28.64s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  User 159: 38,744 points | Total so far: 22,548,990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users:  99%|█████████▉| 181/182 [1:07:47<00:06,  6.23s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  User 179: 169,396 points | Total so far: 24,829,125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users: 100%|██████████| 182/182 [1:07:47<00:00, 22.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING COMPLETE\n",
      "============================================================\n",
      "Successful users: 182\n",
      "Failed/Empty users: 0\n",
      "Total trajectory points: 24,876,978\n",
      "\n",
      "============================================================\n",
      "SAMPLE DATA\n",
      "============================================================\n",
      "\n",
      "First 10 rows:\n",
      "    latitude   longitude  altitude            datetime  user_id  \\\n",
      "0  39.984702  116.318417     492.0 2008-10-23 02:53:04        0   \n",
      "1  39.984683  116.318450     492.0 2008-10-23 02:53:10        0   \n",
      "2  39.984686  116.318417     492.0 2008-10-23 02:53:15        0   \n",
      "3  39.984688  116.318385     492.0 2008-10-23 02:53:20        0   \n",
      "4  39.984655  116.318263     492.0 2008-10-23 02:53:25        0   \n",
      "5  39.984611  116.318026     493.0 2008-10-23 02:53:30        0   \n",
      "6  39.984608  116.317761     493.0 2008-10-23 02:53:35        0   \n",
      "7  39.984563  116.317517     496.0 2008-10-23 02:53:40        0   \n",
      "8  39.984539  116.317294     500.0 2008-10-23 02:53:45        0   \n",
      "9  39.984606  116.317065     505.0 2008-10-23 02:53:50        0   \n",
      "\n",
      "  trajectory_file transportation_mode  \n",
      "0  20081023025304             unknown  \n",
      "1  20081023025304             unknown  \n",
      "2  20081023025304             unknown  \n",
      "3  20081023025304             unknown  \n",
      "4  20081023025304             unknown  \n",
      "5  20081023025304             unknown  \n",
      "6  20081023025304             unknown  \n",
      "7  20081023025304             unknown  \n",
      "8  20081023025304             unknown  \n",
      "9  20081023025304             unknown  \n",
      "\n",
      "Last 10 rows:\n",
      "           latitude   longitude     altitude            datetime  user_id  \\\n",
      "24876968  40.916600  111.713167  3848.425197 2008-03-14 03:32:03      181   \n",
      "24876969  40.915950  111.713517  3838.582677 2008-03-14 03:33:07      181   \n",
      "24876970  40.915600  111.712933  3812.335958 2008-03-14 03:34:26      181   \n",
      "24876971  40.915767  111.712067  3815.616798 2008-03-14 03:36:49      181   \n",
      "24876972  40.915433  111.711450  3841.863517 2008-03-14 03:38:04      181   \n",
      "24876973  40.914867  111.710500  3802.493438 2008-03-14 03:39:56      181   \n",
      "24876974  40.914267  111.710333  3795.931759 2008-03-14 03:41:17      181   \n",
      "24876975  40.912467  111.710667  3795.931759 2008-03-14 03:43:02      181   \n",
      "24876976  40.911517  111.711317  3779.527559 2008-03-14 03:43:28      181   \n",
      "24876977  40.910933  111.711617  3802.493438 2008-03-14 03:43:40      181   \n",
      "\n",
      "         trajectory_file transportation_mode  \n",
      "24876968  20080314025755             unknown  \n",
      "24876969  20080314025755             unknown  \n",
      "24876970  20080314025755             unknown  \n",
      "24876971  20080314025755             unknown  \n",
      "24876972  20080314025755             unknown  \n",
      "24876973  20080314025755             unknown  \n",
      "24876974  20080314025755             unknown  \n",
      "24876975  20080314025755             unknown  \n",
      "24876976  20080314025755             unknown  \n",
      "24876977  20080314025755             unknown  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24876978 entries, 0 to 24876977\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   latitude             float64       \n",
      " 1   longitude            float64       \n",
      " 2   altitude             float64       \n",
      " 3   datetime             datetime64[ns]\n",
      " 4   user_id              int64         \n",
      " 5   trajectory_file      object        \n",
      " 6   transportation_mode  object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(2)\n",
      "memory usage: 1.3+ GB\n",
      "None\n",
      "\n",
      "============================================================\n",
      "DATASET STATISTICS\n",
      "============================================================\n",
      "\n",
      "Total GPS points: 24,876,978\n",
      "Number of users: 182\n",
      "Number of trajectory files: 17784\n",
      "\n",
      "Date range:\n",
      "  Start: 2000-01-01 23:12:19\n",
      "  End: 2012-07-27 08:31:20\n",
      "  Duration: 4590 days 09:19:01\n",
      "\n",
      "Geographic extent:\n",
      "  Latitude: 1.044024 to 400.166667\n",
      "  Longitude: -179.969593 to 179.996942\n",
      "  Altitude: -32647.60 to 107503.30 meters\n",
      "\n",
      "Transportation modes:\n",
      "  unknown: 19,436,362 (78.13%)\n",
      "  walk: 1,590,334 (6.39%)\n",
      "  bus: 1,279,364 (5.14%)\n",
      "  bike: 950,937 (3.82%)\n",
      "  train: 561,031 (2.26%)\n",
      "  car: 514,150 (2.07%)\n",
      "  subway: 286,926 (1.15%)\n",
      "  taxi: 242,802 (0.98%)\n",
      "  airplane: 9,193 (0.04%)\n",
      "  boat: 3,566 (0.01%)\n",
      "  run: 1,975 (0.01%)\n",
      "  motorcycle: 338 (0.00%)\n",
      "\n",
      "Points per user:\n",
      "  Mean: 136687\n",
      "  Median: 35182\n",
      "  Min: 17\n",
      "  Max: 2156994\n",
      "\n",
      "============================================================\n",
      "SAVING DATASET\n",
      "============================================================\n",
      "Saving to: c:\\Users\\subha\\Desktop\\Projects\\dementia_detection\\data\\geolife_combined_dataset.csv\n",
      "✓ Saved 24,876,978 GPS points to CSV\n",
      "✓ Saved sample (10k points) to: c:\\Users\\subha\\Desktop\\Projects\\dementia_detection\\data\\geolife_combined_dataset_sample_10k.csv\n",
      "✓ Saved statistics to: c:\\Users\\subha\\Desktop\\Projects\\dementia_detection\\data\\geolife_combined_dataset_statistics.txt\n",
      "\n",
      "============================================================\n",
      "✓ GEOLIFE DATASET LOADING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Files created:\n",
      "  1. Full dataset: c:\\Users\\subha\\Desktop\\Projects\\dementia_detection\\data\\geolife_combined_dataset.csv\n",
      "  2. Sample (10k): c:\\Users\\subha\\Desktop\\Projects\\dementia_detection\\data\\geolife_combined_dataset_sample_10k.csv\n",
      "  3. Statistics: c:\\Users\\subha\\Desktop\\Projects\\dementia_detection\\data\\geolife_combined_dataset_statistics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class GeoLifeDataLoader:\n",
    "    \"\"\"Load and process Microsoft GeoLife GPS trajectory dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.all_trajectories = []\n",
    "        \n",
    "    def load_plt_file(self, filepath):\n",
    "        \"\"\"\n",
    "        Load a single PLT file\n",
    "        PLT format:\n",
    "        - First 6 lines are headers\n",
    "        - Columns: Latitude, Longitude, 0, Altitude, Days, Date, Time\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read PLT file, skip first 6 header lines\n",
    "            df = pd.read_csv(\n",
    "                filepath, \n",
    "                skiprows=6, \n",
    "                header=None,\n",
    "                names=['latitude', 'longitude', 'zero', 'altitude', 'days', 'date', 'time']\n",
    "            )\n",
    "            \n",
    "            # Combine date and time into datetime\n",
    "            df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "            \n",
    "            # Drop unnecessary columns\n",
    "            df = df[['latitude', 'longitude', 'altitude', 'datetime']]\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filepath}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def load_labels(self, user_folder):\n",
    "        \"\"\"\n",
    "        Load labels.txt if it exists for a user\n",
    "        Format: Start Time, End Time, Transportation Mode\n",
    "        \"\"\"\n",
    "        labels_path = user_folder / 'labels.txt'\n",
    "        \n",
    "        if not labels_path.exists():\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Read labels file (tab-separated)\n",
    "            labels = pd.read_csv(\n",
    "                labels_path,\n",
    "                sep='\\t',\n",
    "                skiprows=1,  # Skip header\n",
    "                names=['start_time', 'end_time', 'transportation_mode']\n",
    "            )\n",
    "            \n",
    "            # Convert to datetime\n",
    "            labels['start_time'] = pd.to_datetime(labels['start_time'])\n",
    "            labels['end_time'] = pd.to_datetime(labels['end_time'])\n",
    "            \n",
    "            return labels\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading labels from {labels_path}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def match_labels_to_trajectory(self, trajectory_df, labels_df):\n",
    "        \"\"\"Match transportation mode labels to trajectory points\"\"\"\n",
    "        \n",
    "        if labels_df is None or labels_df.empty:\n",
    "            trajectory_df['transportation_mode'] = 'unknown'\n",
    "            return trajectory_df\n",
    "        \n",
    "        # Initialize with 'unknown'\n",
    "        trajectory_df['transportation_mode'] = 'unknown'\n",
    "        \n",
    "        # Match each trajectory point to a label\n",
    "        for idx, label_row in labels_df.iterrows():\n",
    "            mask = (\n",
    "                (trajectory_df['datetime'] >= label_row['start_time']) & \n",
    "                (trajectory_df['datetime'] <= label_row['end_time'])\n",
    "            )\n",
    "            trajectory_df.loc[mask, 'transportation_mode'] = label_row['transportation_mode']\n",
    "        \n",
    "        return trajectory_df\n",
    "    \n",
    "    def load_user_trajectories(self, user_id):\n",
    "        \"\"\"Load all trajectories for a single user\"\"\"\n",
    "        \n",
    "        user_folder = self.data_dir / f'{user_id:03d}'\n",
    "        trajectory_folder = user_folder / 'Trajectory'\n",
    "        \n",
    "        if not trajectory_folder.exists():\n",
    "            return None\n",
    "        \n",
    "        # Load labels if available\n",
    "        labels = self.load_labels(user_folder)\n",
    "        \n",
    "        # Get all PLT files\n",
    "        plt_files = list(trajectory_folder.glob('*.plt'))\n",
    "        \n",
    "        if len(plt_files) == 0:\n",
    "            return None\n",
    "        \n",
    "        user_trajectories = []\n",
    "        \n",
    "        for plt_file in plt_files:\n",
    "            # Load trajectory\n",
    "            traj_df = self.load_plt_file(plt_file)\n",
    "            \n",
    "            if traj_df is not None and len(traj_df) > 0:\n",
    "                # Add user and trajectory IDs\n",
    "                traj_df['user_id'] = user_id\n",
    "                traj_df['trajectory_file'] = plt_file.stem\n",
    "                \n",
    "                # Match labels if available\n",
    "                traj_df = self.match_labels_to_trajectory(traj_df, labels)\n",
    "                \n",
    "                user_trajectories.append(traj_df)\n",
    "        \n",
    "        if len(user_trajectories) > 0:\n",
    "            return pd.concat(user_trajectories, ignore_index=True)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def load_all_trajectories(self, start_user=0, end_user=181):\n",
    "        \"\"\"Load trajectories from all users\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"LOADING GEOLIFE DATASET: Users {start_user:03d} to {end_user:03d}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        all_data = []\n",
    "        successful_users = 0\n",
    "        failed_users = 0\n",
    "        total_points = 0\n",
    "        \n",
    "        for user_id in tqdm(range(start_user, end_user + 1), desc=\"Loading users\"):\n",
    "            \n",
    "            user_data = self.load_user_trajectories(user_id)\n",
    "            \n",
    "            if user_data is not None and len(user_data) > 0:\n",
    "                all_data.append(user_data)\n",
    "                successful_users += 1\n",
    "                total_points += len(user_data)\n",
    "                \n",
    "                # Progress update every 20 users\n",
    "                if (user_id + 1) % 20 == 0:\n",
    "                    print(f\"\\n  User {user_id:03d}: {len(user_data):,} points | Total so far: {total_points:,}\")\n",
    "            else:\n",
    "                failed_users += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LOADING COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Successful users: {successful_users}\")\n",
    "        print(f\"Failed/Empty users: {failed_users}\")\n",
    "        print(f\"Total trajectory points: {total_points:,}\")\n",
    "        \n",
    "        if len(all_data) > 0:\n",
    "            combined_df = pd.concat(all_data, ignore_index=True)\n",
    "            self.all_trajectories = combined_df\n",
    "            return combined_df\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def get_dataset_statistics(self, df):\n",
    "        \"\"\"Get summary statistics of the dataset\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DATASET STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nTotal GPS points: {len(df):,}\")\n",
    "        print(f\"Number of users: {df['user_id'].nunique()}\")\n",
    "        print(f\"Number of trajectory files: {df['trajectory_file'].nunique()}\")\n",
    "        \n",
    "        print(f\"\\nDate range:\")\n",
    "        print(f\"  Start: {df['datetime'].min()}\")\n",
    "        print(f\"  End: {df['datetime'].max()}\")\n",
    "        print(f\"  Duration: {df['datetime'].max() - df['datetime'].min()}\")\n",
    "        \n",
    "        print(f\"\\nGeographic extent:\")\n",
    "        print(f\"  Latitude: {df['latitude'].min():.6f} to {df['latitude'].max():.6f}\")\n",
    "        print(f\"  Longitude: {df['longitude'].min():.6f} to {df['longitude'].max():.6f}\")\n",
    "        print(f\"  Altitude: {df['altitude'].min():.2f} to {df['altitude'].max():.2f} meters\")\n",
    "        \n",
    "        print(f\"\\nTransportation modes:\")\n",
    "        mode_counts = df['transportation_mode'].value_counts()\n",
    "        for mode, count in mode_counts.items():\n",
    "            print(f\"  {mode}: {count:,} ({count/len(df)*100:.2f}%)\")\n",
    "        \n",
    "        print(f\"\\nPoints per user:\")\n",
    "        user_stats = df.groupby('user_id').size()\n",
    "        print(f\"  Mean: {user_stats.mean():.0f}\")\n",
    "        print(f\"  Median: {user_stats.median():.0f}\")\n",
    "        print(f\"  Min: {user_stats.min()}\")\n",
    "        print(f\"  Max: {user_stats.max()}\")\n",
    "        \n",
    "        return {\n",
    "            'total_points': len(df),\n",
    "            'num_users': df['user_id'].nunique(),\n",
    "            'num_trajectories': df['trajectory_file'].nunique(),\n",
    "            'date_range': (df['datetime'].min(), df['datetime'].max()),\n",
    "            'transportation_modes': mode_counts.to_dict()\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize loader\n",
    "data_dir = r\"c:\\Users\\subha\\Desktop\\Projects\\dementia_detection\\data\\microsoft_geolife\\Data\"\n",
    "loader = GeoLifeDataLoader(data_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MICROSOFT GEOLIFE GPS TRAJECTORY DATASET LOADER\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nData directory: {data_dir}\")\n",
    "print(f\"\\nThis will load ALL .plt files from 182 user folders (000-181)\")\n",
    "print(f\"Each user has multiple trajectory files in their Trajectory/ subfolder\")\n",
    "\n",
    "# Load all trajectories\n",
    "geolife_data = loader.load_all_trajectories(start_user=0, end_user=181)\n",
    "\n",
    "# Display results\n",
    "if not geolife_data.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SAMPLE DATA\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nFirst 10 rows:\")\n",
    "    print(geolife_data.head(10))\n",
    "    \n",
    "    print(\"\\nLast 10 rows:\")\n",
    "    print(geolife_data.tail(10))\n",
    "    \n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    print(geolife_data.info())\n",
    "    \n",
    "    # Get statistics\n",
    "    stats = loader.get_dataset_statistics(geolife_data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = r\"c:\\Users\\subha\\Desktop\\Projects\\dementia_detection\\data\\geolife_combined_dataset.csv\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SAVING DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Saving to: {output_path}\")\n",
    "    \n",
    "    geolife_data.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved {len(geolife_data):,} GPS points to CSV\")\n",
    "    \n",
    "    # Save a sample for quick testing\n",
    "    sample_path = output_path.replace('.csv', '_sample_10k.csv')\n",
    "    geolife_data.sample(min(10000, len(geolife_data))).to_csv(sample_path, index=False)\n",
    "    print(f\"✓ Saved sample (10k points) to: {sample_path}\")\n",
    "    \n",
    "    # Save statistics\n",
    "    stats_path = output_path.replace('.csv', '_statistics.txt')\n",
    "    with open(stats_path, 'w') as f:\n",
    "        f.write(\"GEOLIFE DATASET STATISTICS\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Total GPS points: {stats['total_points']:,}\\n\")\n",
    "        f.write(f\"Number of users: {stats['num_users']}\\n\")\n",
    "        f.write(f\"Number of trajectories: {stats['num_trajectories']}\\n\")\n",
    "        f.write(f\"\\nDate range: {stats['date_range'][0]} to {stats['date_range'][1]}\\n\")\n",
    "        f.write(f\"\\nTransportation modes:\\n\")\n",
    "        for mode, count in stats['transportation_modes'].items():\n",
    "            f.write(f\"  {mode}: {count:,}\\n\")\n",
    "    \n",
    "    print(f\"✓ Saved statistics to: {stats_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ GEOLIFE DATASET LOADING COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nFiles created:\")\n",
    "    print(f\"  1. Full dataset: {output_path}\")\n",
    "    print(f\"  2. Sample (10k): {sample_path}\")\n",
    "    print(f\"  3. Statistics: {stats_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n❌ No data loaded. Please check the data directory path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3a3be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
